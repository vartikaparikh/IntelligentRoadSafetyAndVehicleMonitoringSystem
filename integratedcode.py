# -*- coding: utf-8 -*-
"""integratedcode.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1rijTu0hzEWVuxn-gLCnRF3WtnX1FRF2J
"""

import numpy as np
import pandas as pd
import os
HOME = os.getcwd()

!nvidia-smi

!pip install ultralytics==8.0.196

from IPython import display
display.clear_output()

import ultralytics
ultralytics.checks()

from ultralytics import YOLO

from IPython.display import display, Image

# Commented out IPython magic to ensure Python compatibility.
# exporting dataset from roboflow
!mkdir {HOME}/datasets
# %cd {HOME}/datasets


!pip install roboflow

from roboflow import Roboflow
rf = Roboflow(api_key="i8iYzppEYGgrh9a6HgGK")
project = rf.workspace("ps1-project-vlayx").project("helmet-final-ciz2y")
version = project.version(2)
dataset = version.download("yolov8")

# Commented out IPython magic to ensure Python compatibility.
# %cd {HOME}

!yolo task=detect mode=train model=yolov8s.pt data={dataset.location}/data.yaml epochs=25 imgsz=800 plots=True

!ls {HOME}/runs/detect/train/

# Commented out IPython magic to ensure Python compatibility.
Image(filename=f'{HOME}/runs/detect/train/confusion_matrix.png', width=600)
Image(filename=f'{HOME}/runs/detect/train/results.png', width=600)

# %cd {HOME}
Image(filename=f'{HOME}/runs/detect/train/val_batch0_pred.jpg', width=600)

# Commented out IPython magic to ensure Python compatibility.
#Validate model
# %cd {HOME}

!yolo task=detect mode=val model={HOME}/runs/detect/train/weights/best.pt data={dataset.location}/data.yaml

# Commented out IPython magic to ensure Python compatibility.
#Inference with model
# %cd {HOME}
!yolo task=detect mode=predict model={HOME}/runs/detect/train/weights/best.pt conf=0.25 source={dataset.location}/test/images save=True

# Function to detect helmet
def detect_helmet(image):
    # Save the uploaded image to a temporary location
    temp_image_path = 'temp_image.jpg'
    cv2.imwrite(temp_image_path, image)

    # YOLOv8 inference command
    inference_command = f"yolo task=detect mode=predict model=./runs/detect/train/weights/best.pt conf=0.25 source={temp_image_path} save=False"

    # Run the YOLOv8 inference command
    result = subprocess.run(inference_command, shell=True, capture_output=True, text=True)

    # Check the output for the 'helmet' label
    if 'helmet' in result.stdout:
        return True
    else:
        return False

"""# OCR (Optical Character Recognition) to detect numberplates of traffic violators"""

#!pip install easyocr
!pip install imutils
!pip install pillow==9.4.0
!pip install pytesseract

import cv2
from matplotlib import pyplot as plt
import imutils
#import easyocr
import pytesseract

'''
img = cv2.imread('/kaggle/input/helmet-test-set/002.jpg')


#convert image to grayscale
gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)

## Display the grayscale image
plt.figure(figsize=(10, 6))
plt.imshow(cv2.cvtColor(gray, cv2.COLOR_BGR2RGB))
plt.title('Grayscale Image')
plt.show()
#plt.imshow(cv2.cvtColor(gray, cv2.COLOR_BGR2RGB))

# Apply Gaussian blur and adaptive thresholding
blurred = cv2.GaussianBlur(gray, (5, 5), 0)
thresh = cv2.adaptiveThreshold(blurred, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C, cv2.THRESH_BINARY_INV, 11, 2)

# Display the thresholded image
plt.figure(figsize=(10, 6))
plt.imshow(cv2.cvtColor(thresh, cv2.COLOR_BGR2RGB))
plt.title('Adaptive Thresholding')
plt.show()

bfilter = cv2.bilateralFilter(gray, 11, 17, 17) #Noise reduction
edged = cv2.Canny(bfilter, 50, 150) #Edge detection

##Display the edges
plt.figure(figsize=(10, 6))
plt.imshow(cv2.cvtColor(edged, cv2.COLOR_BGR2RGB))
plt.title('Edge Detection')
plt.show()


# Find contours
keypoints = cv2.findContours(bfilter.copy(), cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)
contours = imutils.grab_contours(keypoints)
#contours = sorted(contours, key=cv2.contourArea, reverse=True)[:20]

# Draw contours for visualization
img_contours = img.copy()
cv2.drawContours(img_contours, contours, -1, (0, 255, 0), 2)

# Display the image with contours
plt.figure(figsize=(10, 6))
plt.imshow(cv2.cvtColor(img_contours, cv2.COLOR_BGR2RGB))
plt.title('Contours')
plt.show()

# Filter contours based on aspect ratio, area, and additional properties
location = None
min_aspect_ratio = 1
max_aspect_ratio = 10
min_area = 500
max_area = 15000

for contour in contours:
    (x, y, w, h) = cv2.boundingRect(contour)
    aspect_ratio = w / float(h)
    area = cv2.contourArea(contour)
    bounding_box_area = w * h
    extent = area / float(bounding_box_area)

    # Check aspect ratio, area, and extent
    if min_aspect_ratio < aspect_ratio < max_aspect_ratio and min_area < area < max_area and extent > 0.3:
        location = contour
        break

if location is not None:
    # Create a mask for the detected number plate
    mask = np.zeros(gray.shape, np.uint8)
    new_image = cv2.drawContours(mask, [location], 0, 255, -1)
    new_image = cv2.bitwise_and(img, img, mask=mask)

    # Crop the number plate region
    (x, y) = np.where(mask == 255)
    (topx, topy) = (np.min(x), np.min(y))
    (bottomx, bottomy) = (np.max(x), np.max(y))
    cropped_image = gray[topx:bottomx+1, topy:bottomy+1]

    # Display the cropped number plate
    plt.figure(figsize=(10, 6))
    plt.imshow(cv2.cvtColor(cropped_image, cv2.COLOR_BGR2RGB))
    plt.title('Detected Number Plate')
    plt.show()



#plt.imshow(cv2.cvtColor(edged, cv2.COLOR_BGR2RGB))
keypoints = cv2.findContours(edged.copy(), cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)
contours = imutils.grab_contours(keypoints)
contours = sorted(contours, key=cv2.contourArea, reverse=True)[:10]
location = None
for contour in contours:
    approx = cv2.approxPolyDP(contour, 10, True)
    if len(approx) == 4:
        location = approx
        break

'''

#location

'''
mask = np.zeros(gray.shape, np.uint8)
new_image = cv2.drawContours(mask, [location], 0,255, -1)
new_image = cv2.bitwise_and(img, img, mask=mask)
plt.imshow(cv2.cvtColor(new_image, cv2.COLOR_BGR2RGB))
(x,y) = np.where(mask==255)
(x1, y1) = (np.min(x), np.min(y))
(x2, y2) = (np.max(x), np.max(y))
cropped_image = gray[x1:x2+1, y1:y2+1]
cropped_number_plate = cv2.resize(cropped_image, None, fx=2, fy=2, interpolation=cv2.INTER_CUBIC)
cropped_number_plate = cv2.GaussianBlur(cropped_number_plate, (3, 3), 0)
cropped_number_plate = cv2.medianBlur(cropped_number_plate, 3)
cropped_number_plate = cv2.threshold(cropped_number_plate, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)[1]
cropped_number_plate = cv2.bilateralFilter(cropped_number_plate, 11, 17, 17) #Noise reduction
#cropped_number_plate = cv2.Canny(cropped_number_plate, 50, 150) #Edge detection
kernel = np.ones((2, 2), np.uint8)
cropped_number_plate = cv2.morphologyEx(cropped_number_plate, cv2.MORPH_CLOSE, kernel)
plt.imshow(cv2.cvtColor(cropped_image, cv2.COLOR_BGR2RGB))
#cropped_number_plate = cv2.cvtColor(cropped_number_plate, cv2.COLOR_BGR2GRAY)
_, cropped_number_plate = cv2.threshold(cropped_number_plate, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)


##Display the preprocessed image to verify the effect of each step.
plt.figure(figsize=(10, 6))
plt.imshow(cropped_number_plate, cmap='gray')
plt.title('Preprocessed Number Plate')
plt.axis('off')
plt.show()
'''

'''
# Use Tesseract to read the text from the number plate
config = '--psm 4 -c tessedit_char_whitelist=ABCDEFGHIJKLMNOPQRSTUVWXYZ0123456789'
text = pytesseract.image_to_string(cropped_number_plate, config=config)

# Print the OCR results
print("Detected Number Plate Text:")
print(text.strip())
'''

def detect_number_plate(image):

    img = cv2.imread(image)
    #convert image to grayscale
    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)
    # Apply Gaussian blur and adaptive thresholding
    blurred = cv2.GaussianBlur(gray, (5, 5), 0)
    thresh = cv2.adaptiveThreshold(blurred, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C, cv2.THRESH_BINARY_INV, 11, 2)
    bfilter = cv2.bilateralFilter(gray, 11, 17, 17) #Noise reduction
    edged = cv2.Canny(bfilter, 50, 150) #Edge detection
    # Find contours
    keypoints = cv2.findContours(bfilter.copy(), cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)
    contours = imutils.grab_contours(keypoints)
    # Draw contours for visualization
    img_contours = img.copy()
    cv2.drawContours(img_contours, contours, -1, (0, 255, 0), 2)

    # Filter contours based on aspect ratio, area, and additional properties
    location = None
    min_aspect_ratio = 1
    max_aspect_ratio = 10
    min_area = 500
    max_area = 15000

    for contour in contours:
        (x, y, w, h) = cv2.boundingRect(contour)
        aspect_ratio = w / float(h)
        area = cv2.contourArea(contour)
        bounding_box_area = w * h
        extent = area / float(bounding_box_area)

        # Check aspect ratio, area, and extent
        if min_aspect_ratio < aspect_ratio < max_aspect_ratio and min_area < area < max_area and extent > 0.3:
            location = contour
            break

    if location is not None:
        # Create a mask for the detected number plate
        mask = np.zeros(gray.shape, np.uint8)
        new_image = cv2.drawContours(mask, [location], 0, 255, -1)
        new_image = cv2.bitwise_and(img, img, mask=mask)

        # Crop the number plate region
        (x, y) = np.where(mask == 255)
        (topx, topy) = (np.min(x), np.min(y))
        (bottomx, bottomy) = (np.max(x), np.max(y))
        cropped_image = gray[topx:bottomx+1, topy:bottomy+1]



    keypoints = cv2.findContours(edged.copy(), cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)
    contours = imutils.grab_contours(keypoints)
    contours = sorted(contours, key=cv2.contourArea, reverse=True)[:10]
    location = None
    for contour in contours:
        approx = cv2.approxPolyDP(contour, 10, True)
        if len(approx) == 4:
            location = approx
            break

    mask = np.zeros(gray.shape, np.uint8)
    new_image = cv2.drawContours(mask, [location], 0,255, -1)
    new_image = cv2.bitwise_and(img, img, mask=mask)
    plt.imshow(cv2.cvtColor(new_image, cv2.COLOR_BGR2RGB))
    (x,y) = np.where(mask==255)
    (x1, y1) = (np.min(x), np.min(y))
    (x2, y2) = (np.max(x), np.max(y))
    cropped_image = gray[x1:x2+1, y1:y2+1]
    cropped_number_plate = cv2.resize(cropped_image, None, fx=2, fy=2, interpolation=cv2.INTER_CUBIC)
    cropped_number_plate = cv2.GaussianBlur(cropped_number_plate, (3, 3), 0)
    cropped_number_plate = cv2.medianBlur(cropped_number_plate, 3)
    cropped_number_plate = cv2.threshold(cropped_number_plate, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)[1]
    cropped_number_plate = cv2.bilateralFilter(cropped_number_plate, 11, 17, 17) #Noise reduction
    #cropped_number_plate = cv2.Canny(cropped_number_plate, 50, 150) #Edge detection
    kernel = np.ones((2, 2), np.uint8)
    cropped_number_plate = cv2.morphologyEx(cropped_number_plate, cv2.MORPH_CLOSE, kernel)
    plt.imshow(cv2.cvtColor(cropped_image, cv2.COLOR_BGR2RGB))
    #cropped_number_plate = cv2.cvtColor(cropped_number_plate, cv2.COLOR_BGR2GRAY)
    _, cropped_number_plate = cv2.threshold(cropped_number_plate, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)


    ##Display the preprocessed image to verify the effect of each step.
    plt.figure(figsize=(10, 6))
    plt.imshow(cropped_number_plate, cmap='gray')
    plt.title('Preprocessed Number Plate')
    plt.axis('off')
    plt.show()

    # Use Tesseract to read the text from the number plate
    config = '--psm 4 -c tessedit_char_whitelist=ABCDEFGHIJKLMNOPQRSTUVWXYZ0123456789'
    text = pytesseract.image_to_string(cropped_number_plate, config=config)
    '''
    # Print the OCR results
    print("Detected Number Plate Text:")
    print(text.strip())
    '''
    return (text.strip())

"""# Deploying pipeline on Streamlit"""

pip install streamlit

import streamlit as st

# Streamlit app
def main():
    st.title("Helmet Detection and Number Plate OCR")

    # File uploader for image upload
    uploaded_file = st.file_uploader("Choose an image...", type=["jpg", "jpeg", "png"])

    if uploaded_file is not None:
        # Read the image
        image = Image.open(uploaded_file)
        image = np.array(image)

        # Display the uploaded image
        st.image(image, caption='Uploaded Image.', use_column_width=True)

        # Detect helmet
        helmet_detected = detect_helmet(image)

        if not helmet_detected:
            # If no helmet, detect number plate
            numberplate_text = detect_numberplate(image)
            st.write("No helmet detected.")
            st.write("Number plate: ", numberplate_text)
        else:
            st.write("Helmet detected.")

if __name__ == "__main__":
    main()





